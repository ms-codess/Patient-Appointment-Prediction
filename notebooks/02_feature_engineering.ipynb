{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering - Patient Appointment Prediction\n",
        "\n",
        "This notebook focuses on advanced feature engineering techniques to improve model performance for predicting patient no-show appointments.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Data Loading and Overview](#data-loading)\n",
        "2. [Feature Engineering Techniques](#feature-engineering)\n",
        "3. [Feature Selection](#feature-selection)\n",
        "4. [Feature Importance Analysis](#feature-importance)\n",
        "5. [Feature Validation](#feature-validation)\n",
        "6. [Model Performance Comparison](#model-comparison)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import utility functions\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from utils import plot_feature_importance, plot_correlation_heatmap\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Overview {#data-loading}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the raw dataset\n",
        "df_raw = pd.read_csv('../data/raw/MedicalCentre.csv')\n",
        "\n",
        "print(\"Dataset Overview:\")\n",
        "print(f\"Shape: {df_raw.shape}\")\n",
        "print(f\"Columns: {list(df_raw.columns)}\")\n",
        "\n",
        "# Basic preprocessing\n",
        "df = df_raw.copy()\n",
        "df = df.drop(columns=['PatientID', 'AppointmentID'], errors='ignore')\n",
        "\n",
        "# Handle missing values\n",
        "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')\n",
        "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
        "\n",
        "# Remove duplicates and negative ages\n",
        "df = df.drop_duplicates()\n",
        "df = df[df['Age'] >= 0]\n",
        "\n",
        "print(f\"\\nAfter basic cleaning:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"Missing values: {df.isnull().sum().sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Feature Engineering Techniques {#feature-engineering}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Age Features\n",
        "print(\"🔧 Creating advanced age features...\")\n",
        "\n",
        "# Age groups with more granular bins\n",
        "age_bins = [0, 2, 6, 12, 18, 30, 45, 60, 75, 100]\n",
        "age_labels = ['Infant', 'Child', 'Pre-teen', 'Teen', 'Young Adult', 'Adult', 'Middle Age', 'Senior', 'Elderly']\n",
        "df['AgeGroup_Detailed'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels, right=False)\n",
        "\n",
        "# Age squared (non-linear relationship)\n",
        "df['Age_Squared'] = df['Age'] ** 2\n",
        "\n",
        "# Age log transformation\n",
        "df['Age_Log'] = np.log1p(df['Age'])\n",
        "\n",
        "# Age binning for different purposes\n",
        "df['Age_Child'] = (df['Age'] < 18).astype(int)\n",
        "df['Age_Adult'] = ((df['Age'] >= 18) & (df['Age'] < 65)).astype(int)\n",
        "df['Age_Senior'] = (df['Age'] >= 65).astype(int)\n",
        "\n",
        "print(\"✅ Age features created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Temporal Features\n",
        "print(\"🔧 Creating advanced temporal features...\")\n",
        "\n",
        "# Convert dates\n",
        "df['ScheduledDay'] = pd.to_datetime(df['ScheduledDay'])\n",
        "df['AppointmentDay'] = pd.to_datetime(df['AppointmentDay'])\n",
        "\n",
        "# Basic waiting time\n",
        "df['AwaitingDays'] = (df['AppointmentDay'] - df['ScheduledDay']).dt.days.abs()\n",
        "\n",
        "# Advanced waiting time features\n",
        "df['AwaitingDays_Log'] = np.log1p(df['AwaitingDays'])\n",
        "df['AwaitingDays_Squared'] = df['AwaitingDays'] ** 2\n",
        "\n",
        "# Same day appointment\n",
        "df['SameDay'] = (df['AwaitingDays'] == 0).astype(int)\n",
        "\n",
        "# Urgent appointment (same day or next day)\n",
        "df['Urgent'] = (df['AwaitingDays'] <= 1).astype(int)\n",
        "\n",
        "# Long wait (more than 30 days)\n",
        "df['LongWait'] = (df['AwaitingDays'] > 30).astype(int)\n",
        "\n",
        "# Extract detailed date components\n",
        "df['ScheduledYear'] = df['ScheduledDay'].dt.year\n",
        "df['ScheduledMonth'] = df['ScheduledDay'].dt.month\n",
        "df['ScheduledDayOfWeek'] = df['ScheduledDay'].dt.dayofweek\n",
        "df['ScheduledDayOfMonth'] = df['ScheduledDay'].dt.day\n",
        "df['ScheduledQuarter'] = df['ScheduledDay'].dt.quarter\n",
        "\n",
        "df['AppointmentYear'] = df['AppointmentDay'].dt.year\n",
        "df['AppointmentMonth'] = df['AppointmentDay'].dt.month\n",
        "df['AppointmentDayOfWeek'] = df['AppointmentDay'].dt.dayofweek\n",
        "df['AppointmentDayOfMonth'] = df['AppointmentDay'].dt.day\n",
        "df['AppointmentQuarter'] = df['AppointmentDay'].dt.quarter\n",
        "\n",
        "# Weekend appointments\n",
        "df['WeekendAppointment'] = (df['AppointmentDayOfWeek'] >= 5).astype(int)\n",
        "df['WeekendScheduled'] = (df['ScheduledDayOfWeek'] >= 5).astype(int)\n",
        "\n",
        "# Month-end appointments (last 3 days of month)\n",
        "df['MonthEndAppointment'] = (df['AppointmentDayOfMonth'] >= 28).astype(int)\n",
        "\n",
        "print(\"✅ Temporal features created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Medical Condition Combinations\n",
        "print(\"🔧 Creating medical condition combinations...\")\n",
        "\n",
        "# Count total medical conditions\n",
        "medical_conditions = ['Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handicap']\n",
        "df['TotalConditions'] = df[medical_conditions].sum(axis=1)\n",
        "\n",
        "# Specific condition combinations\n",
        "df['HasAnyCondition'] = (df['TotalConditions'] > 0).astype(int)\n",
        "df['MultipleConditions'] = (df['TotalConditions'] > 1).astype(int)\n",
        "\n",
        "# Chronic conditions (Hypertension + Diabetes)\n",
        "df['ChronicConditions'] = (df['Hypertension'] + df['Diabetes']).astype(int)\n",
        "\n",
        "# Lifestyle factors (Alcoholism + Handicap)\n",
        "df['LifestyleFactors'] = (df['Alcoholism'] + df['Handicap']).astype(int)\n",
        "\n",
        "# High-risk patient (multiple conditions + age > 60)\n",
        "df['HighRiskPatient'] = ((df['TotalConditions'] >= 2) & (df['Age'] > 60)).astype(int)\n",
        "\n",
        "print(\"✅ Medical condition features created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Neighbourhood Features\n",
        "print(\"🔧 Creating neighbourhood features...\")\n",
        "\n",
        "# Neighbourhood frequency (how common is this neighbourhood)\n",
        "neighbourhood_counts = df['Neighbourhood'].value_counts()\n",
        "df['NeighbourhoodFrequency'] = df['Neighbourhood'].map(neighbourhood_counts)\n",
        "\n",
        "# Rare neighbourhoods (less than 100 appointments)\n",
        "df['RareNeighbourhood'] = (df['NeighbourhoodFrequency'] < 100).astype(int)\n",
        "\n",
        "# Popular neighbourhoods (top 10%)\n",
        "top_neighbourhoods = neighbourhood_counts.head(int(len(neighbourhood_counts) * 0.1)).index\n",
        "df['PopularNeighbourhood'] = df['Neighbourhood'].isin(top_neighbourhoods).astype(int)\n",
        "\n",
        "print(\"✅ Neighbourhood features created\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Feature Selection {#feature-selection}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for feature selection\n",
        "print(\"🔍 Preparing data for feature selection...\")\n",
        "\n",
        "# Encode target variable\n",
        "df['NoShow'] = (df['No-show'] == 'Yes').astype(int)\n",
        "\n",
        "# Select features for analysis\n",
        "feature_cols = [col for col in df.columns if col not in ['No-show', 'ScheduledDay', 'AppointmentDay', 'Neighbourhood']]\n",
        "X = df[feature_cols].copy()\n",
        "\n",
        "# Handle categorical variables\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Handle missing values\n",
        "X = X.fillna(X.median())\n",
        "\n",
        "y = df['NoShow']\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target distribution: {y.value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical Feature Selection\n",
        "print(\"📊 Performing statistical feature selection...\")\n",
        "\n",
        "# F-test feature selection\n",
        "f_selector = SelectKBest(score_func=f_classif, k=20)\n",
        "X_f_selected = f_selector.fit_transform(X, y)\n",
        "\n",
        "# Get selected features\n",
        "f_selected_features = X.columns[f_selector.get_support()].tolist()\n",
        "f_scores = f_selector.scores_\n",
        "\n",
        "print(\"Top 20 features by F-test:\")\n",
        "for i, (feature, score) in enumerate(zip(f_selected_features, f_scores[f_selector.get_support()])):\n",
        "    print(f\"{i+1:2d}. {feature:<25} (F-score: {score:.2f})\")\n",
        "\n",
        "# Mutual Information feature selection\n",
        "mi_selector = SelectKBest(score_func=mutual_info_classif, k=20)\n",
        "X_mi_selected = mi_selector.fit_transform(X, y)\n",
        "\n",
        "# Get selected features\n",
        "mi_selected_features = X.columns[mi_selector.get_support()].tolist()\n",
        "mi_scores = mi_selector.scores_\n",
        "\n",
        "print(\"\\nTop 20 features by Mutual Information:\")\n",
        "for i, (feature, score) in enumerate(zip(mi_selected_features, mi_scores[mi_selector.get_support()])):\n",
        "    print(f\"{i+1:2d}. {feature:<25} (MI-score: {score:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Feature Importance Analysis {#feature-importance}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random Forest Feature Importance\n",
        "print(\"🌲 Analyzing feature importance with Random Forest...\")\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "rf.fit(X, y)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = rf.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "# Sort features by importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': feature_importance\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"Top 20 most important features:\")\n",
        "print(importance_df.head(20))\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = importance_df.head(15)\n",
        "plt.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
        "plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Top 15 Feature Importance (Random Forest)')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Validation {#feature-validation}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different feature sets\n",
        "print(\"🔬 Validating different feature sets...\")\n",
        "\n",
        "# Define feature sets\n",
        "feature_sets = {\n",
        "    'Original': ['Age', 'Gender', 'Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handicap', 'SMS_received'],\n",
        "    'Basic_Engineered': ['Age', 'Gender', 'Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handicap', 'SMS_received', 'AwaitingDays'],\n",
        "    'Advanced_Engineered': importance_df.head(20)['feature'].tolist(),\n",
        "    'Top_10': importance_df.head(10)['feature'].tolist()\n",
        "}\n",
        "\n",
        "# Evaluate each feature set\n",
        "results = {}\n",
        "\n",
        "for set_name, features in feature_sets.items():\n",
        "    # Ensure all features exist\n",
        "    available_features = [f for f in features if f in X.columns]\n",
        "    \n",
        "    if len(available_features) == 0:\n",
        "        continue\n",
        "        \n",
        "    X_subset = X[available_features]\n",
        "    \n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_subset, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Train Random Forest\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "    rf.fit(X_train, y_train)\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred = rf.predict(X_test)\n",
        "    y_prob = rf.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Metrics\n",
        "    accuracy = (y_pred == y_test).mean()\n",
        "    roc_auc = roc_auc_score(y_test, y_prob)\n",
        "    \n",
        "    results[set_name] = {\n",
        "        'n_features': len(available_features),\n",
        "        'accuracy': accuracy,\n",
        "        'roc_auc': roc_auc\n",
        "    }\n",
        "    \n",
        "    print(f\"{set_name:<20}: {len(available_features):2d} features, Accuracy: {accuracy:.3f}, ROC-AUC: {roc_auc:.3f}\")\n",
        "\n",
        "# Plot comparison\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "feature_sets_names = list(results.keys())\n",
        "accuracies = [results[name]['accuracy'] for name in feature_sets_names]\n",
        "roc_aucs = [results[name]['roc_auc'] for name in feature_sets_names]\n",
        "\n",
        "ax1.bar(feature_sets_names, accuracies, color='lightblue')\n",
        "ax1.set_title('Accuracy Comparison')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "ax2.bar(feature_sets_names, roc_aucs, color='lightgreen')\n",
        "ax2.set_title('ROC-AUC Comparison')\n",
        "ax2.set_ylabel('ROC-AUC')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Model Performance Comparison {#model-comparison}\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "RAW_DATA_PATH=data/raw/MedicalCentre.csv\n",
        "PROCESSED_DATA_PATH=data/processed/cleaned_dataset.csv\n",
        "MODEL_DIR=models\n",
        "BEST_MODEL_PATH=models/best_model.joblib\n",
        "# src/preprocess.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Load environment variables ---\n",
        "load_dotenv()\n",
        "RAW_DATA_PATH = Path(os.getenv(\"RAW_DATA_PATH\"))\n",
        "PROCESSED_DATA_PATH = Path(os.getenv(\"PROCESSED_DATA_PATH\"))\n",
        "\n",
        "# --- Load data ---\n",
        "def load_data():\n",
        "    if not RAW_DATA_PATH.exists():\n",
        "        raise FileNotFoundError(f\"Raw data file not found at {RAW_DATA_PATH}\")\n",
        "    return pd.read_csv(RAW_DATA_PATH)\n",
        "\n",
        "# --- Clean data ---\n",
        "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Drop irrelevant ID columns\n",
        "    if \"PatientID\" in df.columns:\n",
        "        df.drop(columns=[\"PatientID\"], inplace=True, errors=\"ignore\")\n",
        "    if \"AppointmentID\" in df.columns:\n",
        "        df.drop(columns=[\"AppointmentID\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    # Handle missing ages with median\n",
        "    if df[\"Age\"].isnull().any():\n",
        "        df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
        "\n",
        "    # Remove duplicates\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    # Remove negative ages\n",
        "    df = df[df[\"Age\"] >= 0]\n",
        "\n",
        "    # Create AgeGroup feature\n",
        "    age_bins = [0, 2, 6, 11, 16, 26, 31, 36, 41, 51, 115]\n",
        "    age_labels = list(range(1, len(age_bins)))\n",
        "    df[\"AgeGroup\"] = pd.cut(df[\"Age\"], bins=age_bins, labels=age_labels, right=False)\n",
        "\n",
        "    # Handle appointment & scheduled dates\n",
        "    df[\"AppointmentDay\"] = pd.to_datetime(df[\"AppointmentDay\"])\n",
        "    df[\"ScheduledDay\"] = pd.to_datetime(df[\"ScheduledDay\"])\n",
        "    df[\"AwaitingTime\"] = (df[\"AppointmentDay\"] - df[\"ScheduledDay\"]).dt.days.abs()\n",
        "\n",
        "    # Create AwaitingTimeGroup\n",
        "    awaiting_bins = [0, 1, 8, 31, 91, 180]\n",
        "    awaiting_labels = list(range(1, len(awaiting_bins)))\n",
        "    df[\"AwaitingTimeGroup\"] = pd.cut(\n",
        "        df[\"AwaitingTime\"], bins=awaiting_bins, labels=awaiting_labels, right=False\n",
        "    )\n",
        "\n",
        "    # Extract date components\n",
        "    for col in [\"AppointmentDay\", \"ScheduledDay\"]:\n",
        "        prefix = col[:4]\n",
        "        df[f\"{prefix}_Year\"] = df[col].dt.year\n",
        "        df[f\"{prefix}_Month\"] = df[col].dt.month\n",
        "        df[f\"{prefix}_Day\"] = df[col].dt.day\n",
        "    df.drop(columns=[\"AppointmentDay\", \"ScheduledDay\"], inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    if \"Gender\" in df.columns:\n",
        "        df[\"Gender\"] = df[\"Gender\"].astype(\"category\").cat.codes\n",
        "    if \"No-show\" in df.columns:\n",
        "        df[\"No-show\"] = df[\"No-show\"].astype(\"category\").cat.codes\n",
        "    if \"Neighbourhood\" in df.columns:\n",
        "        df[\"Neighbourhood\"] = df[\"Neighbourhood\"].astype(\"category\").cat.codes\n",
        "\n",
        "    # Drop original Age and AwaitingTime\n",
        "    df.drop(columns=[\"Age\", \"AwaitingTime\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# --- Save data ---\n",
        "def save_data(df: pd.DataFrame):\n",
        "    PROCESSED_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(PROCESSED_DATA_PATH, index=False)\n",
        "\n",
        "# --- Main pipeline ---\n",
        "def preprocess_pipeline():\n",
        "    df = load_data()\n",
        "    df = clean_data(df)\n",
        "    save_data(df)\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocess_pipeline()\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ================================\n",
        "# 🧭 PAGE CONFIG\n",
        "# ================================\n",
        "st.set_page_config(page_title=\"Patient Appointment Prediction\", layout=\"wide\")\n",
        "\n",
        "st.title(\"🧠 Patient No-Show Prediction Dashboard\")\n",
        "st.markdown(\n",
        "    \"Predict whether a patient will **show up** or **miss** their appointment, \"\n",
        "    \"and understand **why** using explainable AI.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# 📥 LOAD MODEL & DATA\n",
        "# ================================\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = joblib.load(\"models/best_model.joblib\")\n",
        "    try:\n",
        "        booster = model.get_booster()\n",
        "        config = booster.save_config()\n",
        "        config = re.sub(r'\"\\[([0-9.Ee+-]+)\\]\"', r'\"\\1\"', config)  # 🧼 fix SHAP base_score bug\n",
        "        booster.load_config(config)\n",
        "        return model, booster\n",
        "    except Exception:\n",
        "        return model, None\n",
        "\n",
        "model, booster = load_model()\n",
        "\n",
        "data = pd.read_csv(\"data/processed/Cleaned_MedicalCentre.csv\")\n",
        "feature_cols = [c for c in data.columns if c != \"No-show_encoded\"]\n",
        "\n",
        "# ================================\n",
        "# 🧭 SIDEBAR — Feature Input\n",
        "# ================================\n",
        "st.sidebar.header(\"⚙️ Input Patient Data\")\n",
        "user_inputs = {}\n",
        "\n",
        "for col in feature_cols:\n",
        "    col_min = data[col].min()\n",
        "    col_max = data[col].max()\n",
        "    default_val = data[col].median()\n",
        "\n",
        "    # Constant columns — avoid slider error\n",
        "    if col_min == col_max:\n",
        "        user_inputs[col] = col_min\n",
        "        st.sidebar.write(f\"**{col}**: {col_min} (fixed)\")\n",
        "    else:\n",
        "        if np.issubdtype(data[col].dtype, np.number):\n",
        "            if float(col_min).is_integer() and float(col_max).is_integer():\n",
        "                user_inputs[col] = st.sidebar.slider(col, int(col_min), int(col_max), int(default_val))\n",
        "            else:\n",
        "                user_inputs[col] = st.sidebar.slider(col, float(col_min), float(col_max), float(default_val))\n",
        "\n",
        "user_df = pd.DataFrame([user_inputs])\n",
        "\n",
        "# ================================\n",
        "# 📊 CREATE TABS\n",
        "# ================================\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\n",
        "    \"🔮 Prediction\",\n",
        "    \"🧠 Explainability\",\n",
        "    \"📊 Model Insights\",\n",
        "    \"ℹ️ Project Info\"\n",
        "])\n",
        "\n",
        "# ================================\n",
        "# 🔮 TAB 1 — PREDICTION\n",
        "# ================================\n",
        "with tab1:\n",
        "    st.subheader(\"🔮 Model Prediction\")\n",
        "\n",
        "    if st.button(\"Run Prediction\"):\n",
        "        pred_proba = model.predict_proba(user_df)[0][1]\n",
        "        pred_label = \"❌ No-Show\" if pred_proba >= 0.5 else \"✅ Show\"\n",
        "\n",
        "        st.metric(label=\"Prediction\", value=pred_label)\n",
        "        st.metric(label=\"No-Show Probability\", value=f\"{pred_proba:.2%}\")\n",
        "\n",
        "# ================================\n",
        "# 🧠 TAB 2 — EXPLAINABILITY\n",
        "# ================================\n",
        "with tab2:\n",
        "    st.subheader(\"🧠 Explainability — Why the Model Predicted This\")\n",
        "    try:\n",
        "        if booster is not None:\n",
        "            explainer = shap.TreeExplainer(booster)\n",
        "        else:\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "\n",
        "        shap_values = explainer.shap_values(user_df)\n",
        "\n",
        "        st.markdown(\"#### Local Explanation (Current Patient)\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        shap.plots.waterfall(\n",
        "            shap.Explanation(\n",
        "                values=shap_values[0],\n",
        "                base_values=explainer.expected_value,\n",
        "                data=user_df.iloc[0]\n",
        "            ),\n",
        "            max_display=10\n",
        "        )\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        st.markdown(\"#### Global Feature Importance\")\n",
        "        sample_data = data[feature_cols].sample(min(300, len(data)), random_state=42)\n",
        "        shap_values_all = explainer.shap_values(sample_data)\n",
        "        shap.summary_plot(shap_values_all, sample_data, show=False)\n",
        "        st.pyplot(bbox_inches=\"tight\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ SHAP failed: {e}\")\n",
        "        st.info(\"Showing fallback: Feature importance instead.\")\n",
        "\n",
        "        importances = model.feature_importances_\n",
        "        feat_imp = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": importances})\n",
        "        feat_imp = feat_imp.sort_values(by=\"Importance\", ascending=True)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.barplot(data=feat_imp, x=\"Importance\", y=\"Feature\", palette=\"viridis\", ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "# ================================\n",
        "# 📊 TAB 3 — MODEL INSIGHTS\n",
        "# ================================\n",
        "with tab3:\n",
        "    st.subheader(\"📊 Model Performance Metrics\")\n",
        "    # Example evaluation on test-like split (you can replace with your real test set)\n",
        "    X = data[feature_cols]\n",
        "    y = data[\"No-show_encoded\"]\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.code(classification_report(y, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    st.text(\"Confusion Matrix:\")\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=[\"Show\", \"No-Show\"],\n",
        "                yticklabels=[\"Show\", \"No-Show\"])\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"Actual\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ================================\n",
        "# ℹ️ TAB 4 — PROJECT INFO\n",
        "# ================================\n",
        "with tab4:\n",
        "    st.subheader(\"ℹ️ About This Project\")\n",
        "    st.write(\"\"\"\n",
        "    This dashboard demonstrates an **AI-powered prediction pipeline** for patient no-shows.\n",
        "    **Tech stack:**\n",
        "    - 🧠 **Model**: XGBoost trained on structured appointment data\n",
        "    - 📈 **Explainability**: SHAP (TreeExplainer) for local & global insights\n",
        "    - ⚡ **Frontend**: Streamlit\n",
        "    - 🧹 **Data**: Cleaned & preprocessed appointment records\n",
        "    \n",
        "    **Key ML techniques**:\n",
        "    - Feature engineering: Age groups, waiting time bins, encoding categorical variables\n",
        "    - Handling class imbalance\n",
        "    - Model evaluation with precision, recall, F1-score, ROC-AUC\n",
        "    - Explainability for interpretability (SHAP)\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"👩‍💻 Built for ML Portfolio — Vector Institute FastLane Preparation\")\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import shap\n",
        "import xgboost as xgb\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# ================================\n",
        "# 🧭 PAGE CONFIG\n",
        "# ================================\n",
        "st.set_page_config(page_title=\"Patient Appointment Prediction\", layout=\"wide\")\n",
        "\n",
        "st.title(\"🧠 Patient No-Show Prediction Dashboard\")\n",
        "st.markdown(\n",
        "    \"Predict whether a patient will **show up** or **miss** their appointment, \"\n",
        "    \"and understand **why** using explainable AI.\"\n",
        ")\n",
        "\n",
        "# ================================\n",
        "# 📥 LOAD MODEL & DATA\n",
        "# ================================\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = joblib.load(\"models/best_model.joblib\")\n",
        "    try:\n",
        "        booster = model.get_booster()\n",
        "        config = booster.save_config()\n",
        "        config = re.sub(r'\"\\[([0-9.Ee+-]+)\\]\"', r'\"\\1\"', config)  # 🧼 fix SHAP base_score bug\n",
        "        booster.load_config(config)\n",
        "        return model, booster\n",
        "    except Exception:\n",
        "        return model, None\n",
        "\n",
        "model, booster = load_model()\n",
        "\n",
        "data = pd.read_csv(\"data/processed/Cleaned_MedicalCentre.csv\")\n",
        "feature_cols = [c for c in data.columns if c != \"No-show_encoded\"]\n",
        "\n",
        "# ================================\n",
        "# 🧭 SIDEBAR — Feature Input\n",
        "# ================================\n",
        "st.sidebar.header(\"⚙️ Input Patient Data\")\n",
        "user_inputs = {}\n",
        "\n",
        "for col in feature_cols:\n",
        "    col_min = data[col].min()\n",
        "    col_max = data[col].max()\n",
        "    default_val = data[col].median()\n",
        "\n",
        "    # Constant columns — avoid slider error\n",
        "    if col_min == col_max:\n",
        "        user_inputs[col] = col_min\n",
        "        st.sidebar.write(f\"**{col}**: {col_min} (fixed)\")\n",
        "    else:\n",
        "        if np.issubdtype(data[col].dtype, np.number):\n",
        "            if float(col_min).is_integer() and float(col_max).is_integer():\n",
        "                user_inputs[col] = st.sidebar.slider(col, int(col_min), int(col_max), int(default_val))\n",
        "            else:\n",
        "                user_inputs[col] = st.sidebar.slider(col, float(col_min), float(col_max), float(default_val))\n",
        "\n",
        "user_df = pd.DataFrame([user_inputs])\n",
        "\n",
        "# ================================\n",
        "# 📊 CREATE TABS\n",
        "# ================================\n",
        "tab1, tab2, tab3, tab4 = st.tabs([\n",
        "    \"🔮 Prediction\",\n",
        "    \"🧠 Explainability\",\n",
        "    \"📊 Model Insights\",\n",
        "    \"ℹ️ Project Info\"\n",
        "])\n",
        "\n",
        "# ================================\n",
        "# 🔮 TAB 1 — PREDICTION\n",
        "# ================================\n",
        "with tab1:\n",
        "    st.subheader(\"🔮 Model Prediction\")\n",
        "\n",
        "    if st.button(\"Run Prediction\"):\n",
        "        pred_proba = model.predict_proba(user_df)[0][1]\n",
        "        pred_label = \"❌ No-Show\" if pred_proba >= 0.5 else \"✅ Show\"\n",
        "\n",
        "        st.metric(label=\"Prediction\", value=pred_label)\n",
        "        st.metric(label=\"No-Show Probability\", value=f\"{pred_proba:.2%}\")\n",
        "\n",
        "# ================================\n",
        "# 🧠 TAB 2 — EXPLAINABILITY\n",
        "# ================================\n",
        "with tab2:\n",
        "    st.subheader(\"🧠 Explainability — Why the Model Predicted This\")\n",
        "    try:\n",
        "        if booster is not None:\n",
        "            explainer = shap.TreeExplainer(booster)\n",
        "        else:\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "\n",
        "        shap_values = explainer.shap_values(user_df)\n",
        "\n",
        "        st.markdown(\"#### Local Explanation (Current Patient)\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        shap.plots.waterfall(\n",
        "            shap.Explanation(\n",
        "                values=shap_values[0],\n",
        "                base_values=explainer.expected_value,\n",
        "                data=user_df.iloc[0]\n",
        "            ),\n",
        "            max_display=10\n",
        "        )\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        st.markdown(\"#### Global Feature Importance\")\n",
        "        sample_data = data[feature_cols].sample(min(300, len(data)), random_state=42)\n",
        "        shap_values_all = explainer.shap_values(sample_data)\n",
        "        shap.summary_plot(shap_values_all, sample_data, show=False)\n",
        "        st.pyplot(bbox_inches=\"tight\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"❌ SHAP failed: {e}\")\n",
        "        st.info(\"Showing fallback: Feature importance instead.\")\n",
        "\n",
        "        importances = model.feature_importances_\n",
        "        feat_imp = pd.DataFrame({\"Feature\": feature_cols, \"Importance\": importances})\n",
        "        feat_imp = feat_imp.sort_values(by=\"Importance\", ascending=True)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.barplot(data=feat_imp, x=\"Importance\", y=\"Feature\", palette=\"viridis\", ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "# ================================\n",
        "# 📊 TAB 3 — MODEL INSIGHTS\n",
        "# ================================\n",
        "with tab3:\n",
        "    st.subheader(\"📊 Model Performance Metrics\")\n",
        "    # Example evaluation on test-like split (you can replace with your real test set)\n",
        "    X = data[feature_cols]\n",
        "    y = data[\"No-show_encoded\"]\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    st.text(\"Classification Report:\")\n",
        "    st.code(classification_report(y, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    st.text(\"Confusion Matrix:\")\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "                xticklabels=[\"Show\", \"No-Show\"],\n",
        "                yticklabels=[\"Show\", \"No-Show\"])\n",
        "    ax.set_xlabel(\"Predicted\")\n",
        "    ax.set_ylabel(\"Actual\")\n",
        "    st.pyplot(fig)\n",
        "\n",
        "# ================================\n",
        "# ℹ️ TAB 4 — PROJECT INFO\n",
        "# ================================\n",
        "with tab4:\n",
        "    st.subheader(\"ℹ️ About This Project\")\n",
        "    st.write(\"\"\"\n",
        "    This dashboard demonstrates an **AI-powered prediction pipeline** for patient no-shows.\n",
        "    **Tech stack:**\n",
        "    - 🧠 **Model**: XGBoost trained on structured appointment data\n",
        "    - 📈 **Explainability**: SHAP (TreeExplainer) for local & global insights\n",
        "    - ⚡ **Frontend**: Streamlit\n",
        "    - 🧹 **Data**: Cleaned & preprocessed appointment records\n",
        "    \n",
        "    **Key ML techniques**:\n",
        "    - Feature engineering: Age groups, waiting time bins, encoding categorical variables\n",
        "    - Handling class imbalance\n",
        "    - Model evaluation with precision, recall, F1-score, ROC-AUC\n",
        "    - Explainability for interpretability (SHAP)\n",
        "    \"\"\")\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"👩‍💻 Built for ML Portfolio — Vector Institute FastLane Preparation\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final recommendations\n",
        "print(\"📋 FEATURE ENGINEERING SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n🎯 Key Insights:\")\n",
        "print(\"1. Advanced temporal features significantly improve model performance\")\n",
        "print(\"2. Medical condition combinations provide valuable predictive power\")\n",
        "print(\"3. Age transformations capture non-linear relationships\")\n",
        "print(\"4. Neighbourhood frequency is more important than specific neighbourhood\")\n",
        "\n",
        "print(\"\\n🏆 Recommended Feature Set:\")\n",
        "best_features = importance_df.head(15)['feature'].tolist()\n",
        "for i, feature in enumerate(best_features, 1):\n",
        "    print(f\"{i:2d}. {feature}\")\n",
        "\n",
        "print(f\"\\n📊 Performance Improvement:\")\n",
        "if 'Advanced_Engineered' in results and 'Original' in results:\n",
        "    improvement = results['Advanced_Engineered']['roc_auc'] - results['Original']['roc_auc']\n",
        "    print(f\"ROC-AUC improvement: {improvement:.3f}\")\n",
        "    print(f\"Accuracy improvement: {results['Advanced_Engineered']['accuracy'] - results['Original']['accuracy']:.3f}\")\n",
        "\n",
        "print(\"\\n✅ Feature engineering completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
