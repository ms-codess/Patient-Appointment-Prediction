{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation - Patient Appointment Prediction\n",
        "\n",
        "This notebook provides comprehensive evaluation of trained models including detailed metrics, visualizations, and business insights.\n",
        "\n",
        "## Table of Contents\n",
        "1. [Model Loading and Setup](#model-loading)\n",
        "2. [Performance Metrics](#performance-metrics)\n",
        "3. [Visualization Analysis](#visualization)\n",
        "4. [Business Impact Analysis](#business-impact)\n",
        "5. [Model Interpretability](#interpretability)\n",
        "6. [Recommendations](#recommendations)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, roc_auc_score, \n",
        "    average_precision_score, accuracy_score, precision_score, \n",
        "    recall_score, f1_score, roc_curve, precision_recall_curve\n",
        ")\n",
        "from sklearn.model_selection import validation_curve, learning_curve\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Import utility functions\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "from utils import plot_confusion_matrix, plot_roc_curve, plot_feature_importance\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Loading and Setup {#model-loading}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best trained model\n",
        "try:\n",
        "    model = joblib.load('../models/best_model.joblib')\n",
        "    print(\"‚úÖ Best model loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Model file not found. Please run the training pipeline first.\")\n",
        "    print(\"Run: python src/train.py\")\n",
        "    model = None\n",
        "\n",
        "# Load processed data\n",
        "try:\n",
        "    df = pd.read_csv('../data/processed/cleaned_dataset.csv')\n",
        "    print(\"‚úÖ Processed data loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Processed data not found. Please run preprocessing first.\")\n",
        "    print(\"Run: python src/preprocess.py\")\n",
        "    df = None\n",
        "\n",
        "if model is not None and df is not None:\n",
        "    # Prepare data for evaluation\n",
        "    target_col = 'NoShow' if 'NoShow' in df.columns else 'No-show_encoded'\n",
        "    y = df[target_col]\n",
        "    X = df.drop(columns=[target_col])\n",
        "    \n",
        "    print(f\"\\nüìä Dataset Info:\")\n",
        "    print(f\"Features: {X.shape[1]}\")\n",
        "    print(f\"Samples: {X.shape[0]:,}\")\n",
        "    print(f\"No-show rate: {y.mean():.1%}\")\n",
        "    \n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X)\n",
        "    y_prob = model.predict_proba(X)[:, 1]\n",
        "    \n",
        "    print(f\"\\nüéØ Model Predictions:\")\n",
        "    print(f\"Predicted no-show rate: {y_pred.mean():.1%}\")\n",
        "    print(f\"Average predicted probability: {y_prob.mean():.3f}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot proceed without model and data. Please run the training pipeline.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Performance Metrics {#performance-metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive Performance Analysis\n",
        "if model is not None and df is not None:\n",
        "    print(\"üìà COMPREHENSIVE MODEL EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Calculate all metrics\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    precision = precision_score(y, y_pred, zero_division=0)\n",
        "    recall = recall_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    roc_auc = roc_auc_score(y, y_prob)\n",
        "    pr_auc = average_precision_score(y, y_prob)\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    \n",
        "    print(f\"\\nüéØ Classification Metrics:\")\n",
        "    print(f\"Accuracy:     {accuracy:.4f}\")\n",
        "    print(f\"Precision:    {precision:.4f}\")\n",
        "    print(f\"Recall:       {recall:.4f}\")\n",
        "    print(f\"F1-Score:     {f1:.4f}\")\n",
        "    print(f\"Specificity:  {specificity:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüìä Area Under Curves:\")\n",
        "    print(f\"ROC-AUC:      {roc_auc:.4f}\")\n",
        "    print(f\"PR-AUC:       {pr_auc:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüîç Confusion Matrix:\")\n",
        "    print(f\"True Negatives:  {tn:,}\")\n",
        "    print(f\"False Positives: {fp:,}\")\n",
        "    print(f\"False Negatives: {fn:,}\")\n",
        "    print(f\"True Positives:  {tp:,}\")\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\nüìã Detailed Classification Report:\")\n",
        "    print(classification_report(y, y_pred, target_names=['Show', 'No Show']))\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot evaluate without model and data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualization Analysis {#visualization}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive visualizations\n",
        "if model is not None and df is not None:\n",
        "    print(\"üìä Generating comprehensive visualizations...\")\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y, y_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    axes[0, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "    axes[0, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
        "    axes[0, 0].set_xlim([0.0, 1.0])\n",
        "    axes[0, 0].set_ylim([0.0, 1.05])\n",
        "    axes[0, 0].set_xlabel('False Positive Rate')\n",
        "    axes[0, 0].set_ylabel('True Positive Rate')\n",
        "    axes[0, 0].set_title('ROC Curve')\n",
        "    axes[0, 0].legend(loc=\"lower right\")\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Precision-Recall Curve\n",
        "    precision_vals, recall_vals, _ = precision_recall_curve(y, y_prob)\n",
        "    pr_auc = auc(recall_vals, precision_vals)\n",
        "    \n",
        "    axes[0, 1].plot(recall_vals, precision_vals, color='darkgreen', lw=2, label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
        "    axes[0, 1].set_xlabel('Recall')\n",
        "    axes[0, 1].set_ylabel('Precision')\n",
        "    axes[0, 1].set_title('Precision-Recall Curve')\n",
        "    axes[0, 1].legend(loc=\"lower left\")\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Confusion Matrix\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0],\n",
        "                xticklabels=['Show', 'No Show'], yticklabels=['Show', 'No Show'])\n",
        "    axes[1, 0].set_title('Confusion Matrix')\n",
        "    axes[1, 0].set_xlabel('Predicted')\n",
        "    axes[1, 0].set_ylabel('Actual')\n",
        "    \n",
        "    # 4. Prediction Distribution\n",
        "    axes[1, 1].hist(y_prob[y == 0], bins=50, alpha=0.7, label='Actual Show', color='blue')\n",
        "    axes[1, 1].hist(y_prob[y == 1], bins=50, alpha=0.7, label='Actual No Show', color='red')\n",
        "    axes[1, 1].set_xlabel('Predicted Probability')\n",
        "    axes[1, 1].set_ylabel('Frequency')\n",
        "    axes[1, 1].set_title('Prediction Distribution')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"‚úÖ Visualizations generated successfully!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot generate visualizations without model and data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Business Impact Analysis {#business-impact}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business Impact Analysis\n",
        "if model is not None and df is not None:\n",
        "    print(\"üíº BUSINESS IMPACT ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Calculate business metrics\n",
        "    total_appointments = len(y)\n",
        "    actual_no_shows = y.sum()\n",
        "    predicted_no_shows = y_pred.sum()\n",
        "    \n",
        "    # Cost assumptions (example values)\n",
        "    cost_per_no_show = 150  # Cost of missed appointment slot\n",
        "    cost_per_intervention = 5  # Cost of SMS reminder\n",
        "    \n",
        "    # Current situation (no model)\n",
        "    current_no_show_cost = actual_no_shows * cost_per_no_show\n",
        "    \n",
        "    # With model predictions\n",
        "    high_risk_threshold = 0.5\n",
        "    high_risk_patients = (y_prob >= high_risk_threshold).sum()\n",
        "    \n",
        "    # Assume intervention reduces no-show rate by 30% for high-risk patients\n",
        "    intervention_effectiveness = 0.3\n",
        "    prevented_no_shows = high_risk_patients * intervention_effectiveness\n",
        "    intervention_cost = high_risk_patients * cost_per_intervention\n",
        "    cost_savings = prevented_no_shows * cost_per_no_show\n",
        "    net_savings = cost_savings - intervention_cost\n",
        "    \n",
        "    print(f\"\\nüìä Current Situation:\")\n",
        "    print(f\"Total appointments: {total_appointments:,}\")\n",
        "    print(f\"Actual no-shows: {actual_no_shows:,} ({actual_no_shows/total_appointments:.1%})\")\n",
        "    print(f\"Current no-show cost: ${current_no_show_cost:,}\")\n",
        "    \n",
        "    print(f\"\\nüéØ With Model Intervention:\")\n",
        "    print(f\"High-risk patients identified: {high_risk_patients:,} ({high_risk_patients/total_appointments:.1%})\")\n",
        "    print(f\"Intervention cost: ${intervention_cost:,}\")\n",
        "    print(f\"Prevented no-shows: {prevented_no_shows:.0f}\")\n",
        "    print(f\"Cost savings: ${cost_savings:,}\")\n",
        "    print(f\"Net savings: ${net_savings:,}\")\n",
        "    \n",
        "    print(f\"\\nüí∞ ROI Analysis:\")\n",
        "    roi = (net_savings / intervention_cost) * 100 if intervention_cost > 0 else 0\n",
        "    print(f\"Return on Investment: {roi:.1f}%\")\n",
        "    print(f\"Cost per prevented no-show: ${intervention_cost/prevented_no_shows:.2f}\" if prevented_no_shows > 0 else \"N/A\")\n",
        "    \n",
        "    # Risk stratification\n",
        "    print(f\"\\nüéØ Risk Stratification:\")\n",
        "    low_risk = (y_prob < 0.3).sum()\n",
        "    medium_risk = ((y_prob >= 0.3) & (y_prob < 0.7)).sum()\n",
        "    high_risk = (y_prob >= 0.7).sum()\n",
        "    \n",
        "    print(f\"Low risk (< 30%): {low_risk:,} patients\")\n",
        "    print(f\"Medium risk (30-70%): {medium_risk:,} patients\")\n",
        "    print(f\"High risk (> 70%): {high_risk:,} patients\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot perform business analysis without model and data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Interpretability {#interpretability}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance Analysis\n",
        "if model is not None and df is not None:\n",
        "    print(\"üîç MODEL INTERPRETABILITY ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Try to get feature importance\n",
        "    try:\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importances = model.feature_importances_\n",
        "            feature_names = X.columns\n",
        "        elif hasattr(model, 'named_steps') and hasattr(model.named_steps['clf'], 'feature_importances_'):\n",
        "            importances = model.named_steps['clf'].feature_importances_\n",
        "            feature_names = model.named_steps['prep'].get_feature_names_out()\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Model does not support feature importance analysis\")\n",
        "            importances = None\n",
        "            feature_names = None\n",
        "        \n",
        "        if importances is not None:\n",
        "            # Create importance DataFrame\n",
        "            importance_df = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "            \n",
        "            print(\"\\nüèÜ Top 10 Most Important Features:\")\n",
        "            for i, (_, row) in enumerate(importance_df.head(10).iterrows(), 1):\n",
        "                print(f\"{i:2d}. {row['feature']:<30} {row['importance']:.4f}\")\n",
        "            \n",
        "            # Plot feature importance\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            top_features = importance_df.head(15)\n",
        "            plt.barh(range(len(top_features)), top_features['importance'], color='skyblue')\n",
        "            plt.yticks(range(len(top_features)), top_features['feature'])\n",
        "            plt.xlabel('Feature Importance')\n",
        "            plt.title('Top 15 Feature Importance')\n",
        "            plt.gca().invert_yaxis()\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Feature importance insights\n",
        "            print(f\"\\nüí° Key Insights:\")\n",
        "            print(f\"Most important feature: {importance_df.iloc[0]['feature']}\")\n",
        "            print(f\"Least important feature: {importance_df.iloc[-1]['feature']}\")\n",
        "            \n",
        "            # Cumulative importance\n",
        "            cumulative_importance = importance_df['importance'].cumsum()\n",
        "            features_80_percent = (cumulative_importance <= 0.8).sum()\n",
        "            print(f\"Features explaining 80% of importance: {features_80_percent}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error analyzing feature importance: {e}\")\n",
        "    \n",
        "    # Model complexity analysis\n",
        "    print(f\"\\nüîß Model Complexity:\")\n",
        "    if hasattr(model, 'n_estimators'):\n",
        "        print(f\"Number of estimators: {model.n_estimators}\")\n",
        "    if hasattr(model, 'max_depth'):\n",
        "        print(f\"Maximum depth: {model.max_depth}\")\n",
        "    if hasattr(model, 'n_features_in_'):\n",
        "        print(f\"Number of features: {model.n_features_in_}\")\n",
        "        \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot analyze interpretability without model and data.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Recommendations {#recommendations}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Recommendations and Next Steps\n",
        "if model is not None and df is not None:\n",
        "    print(\"üìã FINAL RECOMMENDATIONS & NEXT STEPS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    print(\"\\nüéØ Model Performance Summary:\")\n",
        "    print(f\"‚Ä¢ ROC-AUC Score: {roc_auc:.3f} ({'Excellent' if roc_auc > 0.8 else 'Good' if roc_auc > 0.7 else 'Fair'})\")\n",
        "    print(f\"‚Ä¢ Precision: {precision:.3f} ({'High' if precision > 0.3 else 'Moderate'})\")\n",
        "    print(f\"‚Ä¢ Recall: {recall:.3f} ({'High' if recall > 0.6 else 'Moderate'})\")\n",
        "    print(f\"‚Ä¢ F1-Score: {f1:.3f} ({'Good' if f1 > 0.4 else 'Moderate'})\")\n",
        "    \n",
        "    print(\"\\nüíº Business Recommendations:\")\n",
        "    print(\"1. üéØ Implement risk-based intervention strategy:\")\n",
        "    print(\"   ‚Ä¢ High-risk patients (>70%): Multiple reminders + phone calls\")\n",
        "    print(\"   ‚Ä¢ Medium-risk patients (30-70%): SMS reminders\")\n",
        "    print(\"   ‚Ä¢ Low-risk patients (<30%): Standard confirmation\")\n",
        "    \n",
        "    print(\"\\n2. üì± Optimize intervention timing:\")\n",
        "    print(\"   ‚Ä¢ Send reminders 1-2 days before appointment\")\n",
        "    print(\"   ‚Ä¢ Follow up on same day for high-risk patients\")\n",
        "    \n",
        "    print(\"\\n3. üìä Monitor and iterate:\")\n",
        "    print(\"   ‚Ä¢ Track intervention effectiveness\")\n",
        "    print(\"   ‚Ä¢ Retrain model monthly with new data\")\n",
        "    print(\"   ‚Ä¢ A/B test different intervention strategies\")\n",
        "    \n",
        "    print(\"\\nüîß Technical Recommendations:\")\n",
        "    print(\"1. üöÄ Model Deployment:\")\n",
        "    print(\"   ‚Ä¢ Deploy model as REST API\")\n",
        "    print(\"   ‚Ä¢ Integrate with appointment scheduling system\")\n",
        "    print(\"   ‚Ä¢ Implement real-time scoring\")\n",
        "    \n",
        "    print(\"\\n2. üìà Model Improvement:\")\n",
        "    print(\"   ‚Ä¢ Collect additional features (weather, traffic, etc.)\")\n",
        "    print(\"   ‚Ä¢ Implement ensemble methods\")\n",
        "    print(\"   ‚Ä¢ Use deep learning for complex patterns\")\n",
        "    \n",
        "    print(\"\\n3. üõ°Ô∏è Model Monitoring:\")\n",
        "    print(\"   ‚Ä¢ Monitor prediction drift\")\n",
        "    print(\"   ‚Ä¢ Track model performance over time\")\n",
        "    print(\"   ‚Ä¢ Implement automated retraining\")\n",
        "    \n",
        "    print(\"\\nüìä Expected Business Impact:\")\n",
        "    print(f\"‚Ä¢ Potential cost savings: ${net_savings:,.0f}\")\n",
        "    print(f\"‚Ä¢ ROI: {roi:.1f}%\")\n",
        "    print(f\"‚Ä¢ Patients to target: {high_risk_patients:,}\")\n",
        "    \n",
        "    print(\"\\n‚úÖ Model is ready for production deployment!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Cannot provide recommendations without model evaluation.\")\n",
        "    print(\"Please run the complete training pipeline first.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
